""" Map feature map transformer encoding the  map as network input.
"""
import math as m
import copy
from typing import List

import numpy as np
import utm

from utility import transformations as trafo
from deep_learning.util import lookups
from deep_learning.losses import target_generator
from deep_learning.util.lookups import create_pole_height_lut


# Class definitions ####################################################################################################
########################################################################################################################


class MapFMT:
    """ Map feature map transformer.
    """
    def __init__(self):
        """
        map_elements_vrf (list[dict]): list of map elements to encode
        fm_shape (list[int]): number of voxels in x-, y-, and z-dimension
        fm_extent (list[list]): feature map extent as [[x_min, x_max], [y_min, y_max], [z_min, z_max]]
        voxel_size (list[float]): [x, y, z] list of voxel sizes (e.g., 0.4 m) in each dimension
        """
        self.map_elements_vrf = None
        self.fm_shape = None
        self.fm_extent = None
        self.voxel_size = None
        self.voxel_centers = None

    def set_map_elements(self, map_elements_vrf):
        self.map_elements_vrf = map_elements_vrf

    def set_shape_and_extent(self, fm_shape, fm_extent):
        self.fm_shape = fm_shape
        self.fm_extent = fm_extent
        self.voxel_size = None
        self.voxel_centers = None

        if self.fm_shape is not None and self.fm_extent is not None:
            self.calculate_voxel_size_and_voxel_centers()

    def calculate_voxel_size_and_voxel_centers(self):
        """ Calculates voxel size and voxel centers based on fm_shape and extent.
        """
        ndims = 3
        voxel_centers = np.zeros((self.fm_shape[0], self.fm_shape[1], self.fm_shape[2], ndims))
        voxel_size = []
        for i in range(ndims):
            voxel_size.append(abs(self.fm_extent[i][0] - self.fm_extent[i][1]) / self.fm_shape[i])
            indices_dim = np.indices(self.fm_shape)[i]
            centers_dim = (indices_dim * voxel_size[i]) + self.fm_extent[i][0] + (voxel_size[i] / 2)
            voxel_centers[:, :, :, i] = centers_dim
        self.voxel_size = voxel_size
        self.voxel_centers = voxel_centers

    def get_filter_configuration_from_fm_type(self, fm_type: str) -> dict:
        """ Provides a configuration for which element type to refine (slower) initial (fast) voxel matching.

        Args:
            fm_type (str): type of map representation (only 'voxels_lut' published).

        Returns:
            dict:bool:
        """
        all_elem_types = lookups.get_all_element_types()
        if fm_type == 'voxels':
            return {elem_type: False for elem_type in all_elem_types}
        elif fm_type == 'voxels_fast':
            return {elem_type: True for elem_type in all_elem_types}
        elif fm_type in ['voxels_balanced', 'voxels_reg', 'voxels_lut']:
            return {
                'poles': True,      # only initial voxel matching
                'signs': False,     # signs are too complex to match well intital voxel matching
                'lights': True,     # only initial voxel matching
            }
        else:
            raise ValueError(f"No setting specified for map fm type '{fm_type}'")

    def create_feature_map_voxels_lut(self, map_fm_element_types: List[str], fm_type: str, settings: dict):
        """ Encodes map elements (lists) into a map representation (tensor) as network input.

        Before encoding the elements, we generate a lookup table (LUT), mapping each element id to
        a list of voxels. For MDD-M (stage 3), this LUT is queried to obtain predictions from respective voxels
        for a specified map element (e.g., averaging predicted bounding boxes).

        First, the LUT is generated by matching elements to voxels.
        Multiple elements may match to the same voxel (conflicts),
        which are resolved subsequently. Second, the map elements included in the LUT are encoded into
        the map representation.

        The voxel matching procedure follows two steps. First, the initial fast matching provides the cubes
        of matching voxels (sufficient for poles and lights). Second, the initial set of matches is further refined
        to account for the rotated shape of signs.

        map_lut_out (dict) comprises:
            map_lut (dict:list): list of element IDs with matched voxels as list of tuples (type->id->list of tuples)
            conflicting_elements (list:dict): list of conflicting elements (debugging and visualization)
            stats (dict:int): case counter (debugging and visualization)

        Args:
            map_fm_element_types list[str]: list of element types which to encode
            fm_type (str): type of map representation
            settings (dict): encoding settings

        Returns:
             map_fm (float tensor): [X, Y, Z, num_map_features] map representation
             map_lut_out (dict): output LUT
        """
        # See config file for definition
        iosa_threshold = settings['pole_iosa_threshold']
        sign_dist_threshold = settings['sign_distance_threshold']
        z_overlap_threshold = settings['sign_z_foreground_threshold']
        sign_default_height = settings['sign_default_height']
        sign_default_width = settings['sign_default_width']
        light_default_height = settings['light_default_height']
        light_default_width = settings['light_default_width']
        pole_default_diameter = settings['pole_default_diameter']
        element_size_factor = settings['element_size_factor']
        use_pre_filtering_only = self.get_filter_configuration_from_fm_type(fm_type)

        # Create zero-filled 3D tensor (using fm_shape and element types as features)
        # Features: one-hot vector for all element types
        all_elem_types = lookups.get_all_element_types()
        num_map_fm_features = len(all_elem_types)
        num_map_fm_features += 7
        map_fm = np.zeros((self.fm_shape[0], self.fm_shape[1], self.fm_shape[2], num_map_fm_features))
        _, elem_type_lut = lookups.get_element_type_naming_lut()
        poles_heights_per_cls = create_pole_height_lut()
        map_lut = {'lights': {}, 'poles': {}, 'signs': {}}

        # Statistics for debugging purposes
        stats = {
            'case_1': 0,
            'case_2': 0,
            'case_3': 0,
        }

        conflicting_elements_acc = []  # accumulator for conflicting elements

        # Priority of elements for voxel matching: lights, signs, poles
        priority = ['lights', 'signs', 'poles']
        map_elements_map_fm = []
        for elem_type in priority:
            if elem_type in map_fm_element_types:
                elements_type = [e for e in self.map_elements_vrf if elem_type_lut[e['type']] is elem_type]
                map_elements_map_fm.extend(elements_type)

        # Cluster signs (find groups of vertically stacked elements)
        # Mark the lowest and highest sign in a cluster of vertically stacked elements
        # For both lowest and highest sign, add voxels below and above as matches
        # Such procedure includes their predictions during post-processing and refines predicted final bounding shape
        signs = [e for e in self.map_elements_vrf if elem_type_lut[e['type']] is 'signs']
        clusters = cluster_elements(signs)
        for c in clusters:
            num_stack = len(c)
            if num_stack < 2:
                continue
            c = sorted(c, key=lambda d: d['z_vrf'])  # sort by z_min to z_max
            c[0]['lowest'] = True
            c[num_stack - 1]['highest'] = True

        # Match elements to voxel grid
        for elem in map_elements_map_fm:
            elem_type = elem_type_lut[elem['type']]
            elem_id = elem['id']

            if elem_type not in map_fm_element_types:
                continue

            map_lut[elem_type][elem_id] = []
            check_z_overlap = elem_type in ['signs', 'lights']

            # Get candidates matching test (all voxels within radius of the element) | prefiltering
            elem_width = elem[lookups.get_main_size_features()[elem_type]]
            elem_height = elem['height'] if elem_type != 'poles' else poles_heights_per_cls[elem['cls'].lower()]

            # Shift lowest and highest element in a vertical sign cluster to include voxels below and above
            # (only for voxel matching, regression features remain exact)
            offset = 0
            if 'lowest' in elem.keys():
                elem_height += .4
                offset -= .2
            if 'highest' in elem.keys():
                elem_height += .4
                offset += .2

            x_vrf = elem['x_vrf']
            y_vrf = elem['y_vrf']
            z_vrf = elem['z_vrf'] + offset

            # Initial matching
            # Create distances maps
            dx_map = self.voxel_centers[:, :, :, 0] - x_vrf
            dy_map = self.voxel_centers[:, :, :, 1] - y_vrf
            dz_map = self.voxel_centers[:, :, :, 2] - z_vrf

            thres_dist = max(elem_width, self.voxel_size[0]) * element_size_factor
            thres_height = max(elem_height, self.voxel_size[2]) * element_size_factor

            # Get voxels in xy dim that fulfill condition
            match_map_xy = np.logical_and(abs(dx_map) < thres_dist, abs(dy_map) < thres_dist)

            # Check z-dimension
            if elem_type == 'poles':
                upper_thres = max(elem_height, self.voxel_size[2])
                # Little buffer to match voxel slightly below the base point of a pole
                lower_thres = -self.voxel_size[2] / 2
                match_map_z = np.logical_and(lower_thres < dz_map, dz_map < upper_thres)
                match_map = match_map_xy & match_map_z
            else:
                match_map = np.logical_and(match_map_xy, abs(dz_map) < thres_height)
            indices_map = match_map.nonzero()  # get indices where condition is satisfied

            # Only apply initial matching
            if use_pre_filtering_only[elem_type]:
                for ix, iy, iz in zip(indices_map[0], indices_map[1], indices_map[2]):
                    voxel = (ix, iy, iz)
                    if voxel not in map_lut[elem_type][elem_id]:
                        map_lut[elem_type][elem_id].append(voxel)

            # Refine matching (only for signs in 'voxels_lut' setting)
            else:
                # Find the closest voxel to ensure match despite further conditions
                dmap = np.sqrt(dx_map ** 2 + dy_map ** 2 + dz_map ** 2)
                indices_min = np.unravel_index(dmap.argmin(), dmap.shape)
                ix, iy, iz = indices_min[0], indices_min[1], indices_min[2]

                voxel = (ix, iy, iz)
                if voxel not in map_lut[elem_type][elem_id]:
                    map_lut[elem_type][elem_id].append(voxel)

                # Iterate over other candidates for matching
                line_seg = None
                if elem_type == 'signs':
                    line_seg = target_generator.calculate_line_segment(x_vrf, y_vrf, elem_width, elem['yaw_vrf'])

                for ix, iy, iz in zip(indices_map[0], indices_map[1], indices_map[2]):
                    voxel = self.voxel_centers[ix, iy, iz, :]

                    if elem_type == 'signs':
                        p = np.array([voxel[0], voxel[1]])
                        dist = target_generator.point_to_line_dist(p, line_seg)
                        is_xy_match = dist <= sign_dist_threshold
                    else:
                        # Get iosa for circular overlap with voxels in x/y-dimension
                        dist = m.sqrt((voxel[0] - x_vrf) ** 2 + (voxel[1] - y_vrf) ** 2)
                        iosa = target_generator.iosa_two_circles(dist, elem_width, self.voxel_size[0])
                        is_xy_match = iosa >= iosa_threshold

                    if is_xy_match and check_z_overlap:
                        z_overlap = target_generator.line_overlap(p1=z_vrf, len1=elem_height, p2=voxel[2],
                                                                  len2=self.voxel_size[2])
                        is_match = is_xy_match and z_overlap >= z_overlap_threshold
                    else:
                        is_match = is_xy_match

                    if is_match:
                        voxel = (ix, iy, iz)
                        if voxel not in map_lut[elem_type][elem_id]:
                            map_lut[elem_type][elem_id].append(voxel)

            # Get voxel candidates and check for conflicts (= ambiguous voxels matched to multiple elements)
            # Multiple elements may match to the same voxels
            candidate_voxels = map_lut[elem_type][elem_id]
            conflicting_elements = self.query_lut_for_conflicts(map_lut, candidate_voxels, elem_id)
            if conflicting_elements:
                conflicting_elements_acc.extend(conflicting_elements)  # extend accumulator of conflicts

            # Resolve conflicts
            num_voxels_new = len(map_lut[elem_type][elem_id])
            for conflicting_element in conflicting_elements:
                elem['conflicting'] = True
                conflicting_voxels = conflicting_element['conflicting_voxels']
                num_voxels_conflict = len(conflicting_voxels)

                # Common case 1: fewer conflicts than new voxels
                # Remove conflicts from current element
                if num_voxels_conflict < num_voxels_new:
                    for conflict_voxel in conflicting_voxels:
                        # Voxels / element may have been removed by another conflicting element
                        if elem_id in map_lut[elem_type]:
                            if conflict_voxel in map_lut[elem_type][elem_id]:
                                map_lut[elem_type][elem_id].remove(conflict_voxel)
                    stats['case_1'] += 1

                # More conflicts than number of new voxels
                else:
                    # Try to carve out conflicts from conflicting, old element existing in lut
                    conflict_type = conflicting_element['type']
                    conflict_id = conflicting_element['id']
                    remaining_voxels = copy.deepcopy(map_lut[conflict_type][conflict_id])

                    for conflict_voxel in conflicting_voxels:
                        if conflict_voxel in remaining_voxels:
                            remaining_voxels.remove(conflict_voxel)

                    num_remaining_voxels = len(remaining_voxels)

                    # Case 2: Conflicting element has voxels left
                    if num_remaining_voxels >= 1:
                        map_lut[conflict_type][conflict_id] = remaining_voxels
                        stats['case_2'] += 1
                        elem['case_2'] = True

                    # Case 3: New element in full conflict, cannot be included in map representation
                    # Remove from map LUT
                    # Such elements cannot be evaluated by MDD-M (stage 3) ...
                    # and will be counted as false negatives (FN) during evaluation
                    else:
                        map_lut[elem_type].pop(elem_id, None)
                        elem['excluded_from_lut'] = True
                        stats['case_3'] += 1

        # Sanity check: remove elements for which no voxels are left (e.g., multiple conflicting elements in case 1)
        for elem_type in map_lut:
            remove_ids = []
            for elem_id in map_lut[elem_type]:
                if not map_lut[elem_type][elem_id]:
                    # print("[Warning] lut generation: empty element.")
                    remove_ids.append(elem_id)
            for elem_id in remove_ids:
                map_lut[elem_type].pop(elem_id, None)
                elem = [e for e in map_elements_map_fm if e['id'] == elem_id][0]
                elem['excluded_from_lut'] = True

        # Encode map elements included in LUT to provide the map representation
        for elem_type in map_lut:
            for elem_id in map_lut[elem_type]:
                for elem in self.map_elements_vrf:
                    if elem['id'] == elem_id:
                        # Get element data
                        x_vrf = elem['x_vrf']
                        y_vrf = elem['y_vrf']
                        z_vrf = elem['z_vrf']

                        object_data = [x_vrf, y_vrf, z_vrf]
                        if elem_type == 'lights':
                            object_data += [
                                np.log(elem['width'] / light_default_width),  # width
                                np.log(elem['height'] / light_default_height),  # height
                                m.sin(m.radians(elem['yaw_vrf'])),  # yaw_sin
                                m.cos(m.radians(elem['yaw_vrf']))  # yaw_cos
                            ]
                        elif elem_type == 'poles':
                            object_data += [
                                np.log(elem['diameter'] / pole_default_diameter)
                            ]
                        elif elem_type == 'signs':
                            object_data += [
                                np.log(elem['width'] / sign_default_width),  # width
                                np.log(elem['height'] / sign_default_height),  # height
                                m.sin(m.radians(elem['yaw_vrf'])),  # yaw_sin
                                m.cos(m.radians(elem['yaw_vrf']))  # yaw_cos
                            ]

                        elem_one_hot_idx = all_elem_types.index(elem_type)
                        for voxel in map_lut[elem_type][elem_id]:
                            map_fm[voxel[0], voxel[1], voxel[2], elem_one_hot_idx] = 1
                            map_fm = self.set_regression_values(map_fm, [voxel[0], voxel[1], voxel[2]], object_data)

        map_lut_out = {
            'lut': map_lut,
            'conflicting_elements': conflicting_elements_acc,
            'stats': stats
        }

        return map_fm, map_lut_out

    def query_lut_for_conflicts(self, map_lut, candidate_voxels, cur_elem_id):
        # Check if voxel candidates are already matched with another object
        conflicting_elements = []
        for elem_type in map_lut.keys():
            for id_lut in map_lut[elem_type]:
                # Skip current element
                if id_lut == cur_elem_id:
                    continue

                # Get previously assigned voxels
                voxels_lut = map_lut[elem_type][id_lut]
                conflicting_voxels = []
                for voxel in candidate_voxels:
                    if voxel in voxels_lut:
                        conflicting_voxels.append(voxel)

                # If conflicts with other elements are found: append to conflicting elements
                if conflicting_voxels:
                    conflicting_element = {
                        'type': elem_type,
                        'id': id_lut,
                        'conflicting_voxels': conflicting_voxels
                    }
                    conflicting_elements.append(conflicting_element)

        return conflicting_elements

    def set_regression_values(self, map_fm, indices, object_data):
        ix = indices[0]
        iy = indices[1]
        iz = indices[2]

        anchor_x = self.voxel_centers[ix, iy, iz, 0]
        anchor_y = self.voxel_centers[ix, iy, iz, 1]
        anchor_z = self.voxel_centers[ix, iy, iz, 2]

        idx_offset = 3  # index offset for one-hot element values
        map_fm[ix, iy, iz, idx_offset + 0] = (object_data[0] - anchor_x) / self.voxel_size[0]
        map_fm[ix, iy, iz, idx_offset + 1] = (object_data[1] - anchor_y) / self.voxel_size[1]
        map_fm[ix, iy, iz, idx_offset + 2] = (object_data[2] - anchor_z) / self.voxel_size[2]

        idx_offset += 3
        for i, value in enumerate(object_data[3:]):
            map_fm[ix, iy, iz, idx_offset + i] = value

        return map_fm


# Module functions #####################################################################################################
########################################################################################################################

def cluster_elements(elements, thres_d=.5):
    """ Clusters elements using their x-y-position.

    Args:
        elements (list[dict]): elements to cluster
        thres_d (float): association distance [meter]

    Returns:
        clusters (list[list]): list of clusters (groups of elements as lists)
    """

    # Init
    x_vec = [e['x_utm'] for e in elements]
    y_vec = [e['y_utm'] for e in elements]
    num_elements = len(elements)
    i_vec = list(range(0, num_elements))    # indices vector
    d_vec = np.zeros(num_elements)          # distance vector
    cmp_matrix = np.column_stack((x_vec, y_vec, i_vec, d_vec))   # compare matrix for fast clustering

    # Cluster elements
    used_indices = []
    clusters = []
    for _, element in enumerate(elements):
        # Find closest elements
        x = element['x_utm']
        y = element['y_utm']
        d_vec = np.sqrt((cmp_matrix[:, 0] - x) ** 2 + (cmp_matrix[:, 1] - y) ** 2)

        # Sort cmp_matrix by entry 3 (d_vec)
        cmp_matrix[:, 3] = d_vec
        cmp_matrix = cmp_matrix[cmp_matrix[:, 3].argsort()]
        close_matrix = cmp_matrix[cmp_matrix[:, 3] < thres_d]
        n_close = close_matrix.shape[0]

        # Append elements to cluster
        cluster = []
        for i_entry in range(0, n_close):
            index = int(close_matrix[i_entry, 2])

            if index not in used_indices:
                used_indices.append(index)
                cluster.append(elements[index])
        clusters.append(cluster)

    return clusters


def filter_elements_by_fm_extent(map_elements_vrf, fm_extent):
    """ Filters map elements to be within a given feature map extent.

    Args:
        map_elements_vrf list[dict]: list of map elements in vehicle reference frame (VRF)
        fm_extent (list[list]): feature map extent as [[x_min, x_max], [y_min, y_max], [z_min, z_max]]

    Returns:
        map_elements_vrf list[dict]: filtered elements
    """

    # Remove elements with invalid coordinates
    map_elements_vrf = [e for e in map_elements_vrf if not (np.isnan(e['x_vrf']) or np.isnan(e['y_vrf']))]
    # Get positions
    x = [e['x_vrf'] for e in map_elements_vrf]
    y = [e['y_vrf'] for e in map_elements_vrf]
    x = np.array(x)
    y = np.array(y)
    np.seterr(all='raise')
    # Filter by extent
    valid_x = np.logical_and(x > fm_extent[0][0], x < fm_extent[0][1])
    valid_y = np.logical_and(y > fm_extent[1][0], y < fm_extent[1][1])
    valid_indices = np.where(np.logical_and(valid_x, valid_y))[0]
    map_elements_vrf = [map_elements_vrf[i] for i in valid_indices]

    return map_elements_vrf


def transform_elements_wgs_to_vrf(map_elements_wgs, position_utm, orientation_utm):
    """ Transforms map elements from WGS84 to VRF.

    Args:
        map_elements_wgs (list[dict]): list of map elements in WGS84
        position_utm (list[float]): [x_utm, y_utm, z_utm] position in UTM
        orientation_utm (list[float]): [pitch, roll, yaw] orientation of the vehicle in UTM

    Returns:
        map_elements_vrf (list[dict]): list of map elements in WGS84
    """

    x = []
    y = []
    z = []

    # Read positional information
    for element in map_elements_wgs:
        lat = element['lat']
        lon = element['lon']
        z_val = element['z_utm']

        pos_utm = utm.from_latlon(lat, lon)
        x.append(pos_utm[0])
        y.append(pos_utm[1])
        z.append(z_val)

    # Create np array and transform
    points_utm = np.array([x, y, z])  # [3, N]
    points_vrf = trafo.transform_points_utm_to_vrf(points_utm, position_utm, orientation_utm)

    # Set positional information
    points_vrf = points_vrf.T

    map_elements_vrf = map_elements_wgs
    for i, element in enumerate(map_elements_vrf):
        element['x_vrf'] = points_vrf[i, 0]
        element['y_vrf'] = points_vrf[i, 1]
        element['z_vrf'] = points_vrf[i, 2]

        # Transform yaw to VRF
        if 'yaw_utm' in element:
            yaw_offset = 90 if element['type'] == 'TrafficLight' else 0
            yaw = element['yaw_utm']
            element['yaw_vrf'] = -yaw + yaw_offset - orientation_utm[2]

    return map_elements_vrf


def join_vertically_stacked_signs(map_elements: list,
                                  lower_shapes_to_consider: list = None,
                                  upper_shapes_to_consider: list = None,
                                  width_threshold=0.1
                                  ) -> list:
    """ Join vertically stacked signs to a single object if they cannot be distinguished from the point cloud alone.


    Specifically, we join rectangular signs with a (too) small vertical gap and similar width (10 cm).
    However, that's an exception case.

    Args:
        map_elements (list[dict]): list of signs to possible join
        lower_shapes_to_consider (list[str]): list of shapes to consider for joining (lower sign)
        upper_shapes_to_consider (list[str)]: list of shapes to consider for joining (upper sign)
        width_threshold (float): width threshold below which to fuse vertically stacked signs.

    Returns:
        filtered_elements (list[dict]): list of filtered elements with fused verticaly stacked signs
    """
    all_shapes = ['circle', 'diamond', 'directions', 'rectangle', 'triangle_down', 'triangle_up']
    if lower_shapes_to_consider is None:
        lower_shapes_to_consider = all_shapes
    if upper_shapes_to_consider is None:
        upper_shapes_to_consider = all_shapes
    relevant_shapes = list(set(lower_shapes_to_consider + upper_shapes_to_consider))

    unknown_shapes = [shape for shape in relevant_shapes if shape not in all_shapes]
    if len(unknown_shapes) > 0:
        raise ValueError(f"Unknown sign shape(s): {', '.join(unknown_shapes)}")

    # Split signs with eligible shapes from other map elements
    candidate_signs, other_elements = [], []
    for el in map_elements:
        if el['type'] == 'TrafficSign' and el['shape'] in relevant_shapes:
            candidate_signs.append(el)
        else:
            other_elements.append(el)

    # Join possible candidates
    signs_out = []
    while len(candidate_signs) > 0:
        candidate = candidate_signs[0]
        candidate_signs = candidate_signs[1:]  # remove candidate from list

        # Compare with every other candidate left
        joined = False
        for sign in candidate_signs:
            if check_signs_vertical_stack(
                    candidate, sign, lower_shapes_to_consider, upper_shapes_to_consider, width_threshold):
                joined = True
                merged_sign = merge_two_stacked_signs(candidate, sign)
                candidate_signs.append(merged_sign)
                candidate_signs.remove(sign)
                break

        # No signs to join left -> candidate has final form and can be put in output list
        if not joined:
            signs_out.append(candidate)

    filtered_elements = other_elements + signs_out
    return filtered_elements


def check_signs_vertical_stack(sign_1, sign_2,
                               lower_shapes_to_consider,
                               upper_shapes_to_consider,
                               width_diff_threshold):
    """ Check conditions if vertically stacked signs should better be fused.

    Args:
        sign_1 (dict): first sign to test
        sign_2 (dict): second sign to test
        lower_shapes_to_consider (list[str]): list of shapes to consider for joining
        upper_shapes_to_consider (list[str]): list of shapes to consider for joining
        width_diff_threshold (float): width threshold below which to fuse vertically stacked signs.

    Returns:
        is_stacked (bool): True if signs are stacked, not distinguishable, and should be joint.
    """
    # Determines if two signs are vertically stacked on top of each other
    dist_xy_threshold = 0.15  # m
    yaw_threshold = 5  # degrees
    dist_z_threshold = 0.05  # distance between sign borders (not centers)
    is_stacked = False

    # Criterion 1 (eligible shapes)
    upper_sign = sign_1 if sign_1['z_utm'] > sign_2['z_utm'] else sign_2
    lower_sign = sign_1 if sign_1['z_utm'] <= sign_2['z_utm'] else sign_2
    if lower_sign['shape'] in lower_shapes_to_consider and upper_sign['shape'] in upper_shapes_to_consider:

        # Criterion 2 (plane distance)
        dx = sign_1['x_utm'] - sign_2['x_utm']
        dy = sign_1['y_utm'] - sign_2['y_utm']
        dist_xy = m.sqrt(dx ** 2 + dy ** 2)
        if dist_xy < dist_xy_threshold:

            # Criterion 3 (orientation)
            angle_difference_abs = 180 - abs(abs(sign_1['yaw_utm'] - sign_2['yaw_utm']) - 180)
            if angle_difference_abs < yaw_threshold or angle_difference_abs - 180 < yaw_threshold:

                # Criterion 4 (vertical gap)
                center_distance = abs(sign_1['z_utm'] - sign_2['z_utm'])
                vertical_gap = center_distance - (sign_1['height'] / 2 + sign_2['height'] / 2)
                if vertical_gap < dist_z_threshold:

                    # Criterion 5 (difference in width)
                    if abs(sign_1['width'] - sign_2['width']) < width_diff_threshold:
                        is_stacked = True

    return is_stacked


def merge_two_stacked_signs(sign_1, sign_2):
    """ Merges two signs into a single object.

    Args:
        sign_1 (dict): first sign to merge
        sign_2 (dict): second sign

    Returns:
        sign_merged (dict): merged sign
    """
    # Width
    upper_sign = sign_1 if sign_1['z_utm'] > sign_2['z_utm'] else sign_2
    lower_sign = sign_1 if sign_1['z_utm'] <= sign_2['z_utm'] else sign_2
    sign_merged = upper_sign.copy()  # use upper sign as base (ID etc.) to be consistent

    sign_merged['width'] = max(sign_1['width'], sign_2['width'])

    # Height
    center_distance = abs(sign_1['z_utm'] - sign_2['z_utm'])
    height_merged = center_distance + (sign_1['height'] / 2 + sign_2['height'] / 2)
    sign_merged['height'] = height_merged

    # z_utm
    lower_border_z = lower_sign['z_utm'] - lower_sign['height'] / 2
    z_utm_merged = (lower_border_z + lower_border_z + height_merged) / 2
    sign_merged['z_utm'] = z_utm_merged

    # Set shape to 'Rectangle' since it will now likely resemble this shape most
    # sign_merged['shape'] = 'Rectangle'
    # yaw, x_utm, y_utm, lat, lon, height_above_ground, etc. -> keep from lower sign

    return sign_merged


def limit_yaw_value(map_elements_vrf):
    """ Limits the orientation value of elements.

    Specifically, we limit yaw for signs to a value range of 180Â° as the network cannot easily
    distinguish between front and backside.

    Args:
        map_elements_vrf (list[dict]): list of elements

    Returns:
        map_elements_vrf (list[dict]): modified list of elements with orientation value limited.

    """
    # Iterate over all elements and limit orientation value
    for element in map_elements_vrf:
        if 'yaw_vrf' in element:
            yaw_vrf = element['yaw_vrf']
            yaw_vrf %= 360

            if element['type'] == 'TrafficSign':
                # Limit sign orientation to -90 + 90
                if yaw_vrf >= 270:
                    yaw_vrf = -(360 - yaw_vrf)
                elif 90 < yaw_vrf < 270:
                    yaw_vrf -= 180

            element['yaw_vrf'] = yaw_vrf

    return map_elements_vrf
